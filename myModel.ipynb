{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Optimizer\", \"Momentum/Weight Decay\", \"Learning Rate\", \"Best Accuracy\",\"Total Time\", \"Model ID\",\n",
    "               \"Train Losses\", \"Train Accuracies\", \"Validation Losses\", \"Validation Accuracies\"]\n",
    "\n",
    "with open('Results.tsv', 'a') as f:\n",
    "    if os.stat('Results.tsv').st_size == 0:  # Check if file is empty\n",
    "        f.write(\"\\t\".join(headers) + \"\\n\")  # Write headers only if file is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "original_tsv = '2000_files.tsv'\n",
    "test_tsv = 'test.tsv'\n",
    "train_tsv = 'train.tsv'\n",
    "\n",
    "# Load original data into DataFrame\n",
    "df = pd.read_csv(original_tsv, sep='\\t', header=0)\n",
    "\n",
    "# Select 100 female and 750 male rows randomly for test.tsv\n",
    "if not os.path.exists(test_tsv):\n",
    "    female_rows_test = df[df['gender'].str.lower() == 'female_feminine'].sample(n=500, random_state=42)\n",
    "    male_rows_test = df[df['gender'].str.lower() == 'male_masculine'].sample(n=500, random_state=42)\n",
    "    \n",
    "    selected_rows_test = pd.concat([female_rows_test, male_rows_test])\n",
    "    \n",
    "    # Save selected rows for testing\n",
    "    selected_rows_test.to_csv(test_tsv, sep='\\t', index=False)\n",
    "    print(f\"Created {test_tsv} with selected rows for testing.\")\n",
    "else:\n",
    "    print(f\"{test_tsv} already exists. Skipping creation of the test file.\")\n",
    "\n",
    "# Select remaining rows for train.tsv\n",
    "if not os.path.exists(train_tsv):\n",
    "    # Get indices of rows selected for test.tsv\n",
    "    test_indices = selected_rows_test.index\n",
    "    \n",
    "    # Select rows not in test.tsv for training\n",
    "    df_train = df[~df.index.isin(test_indices)]\n",
    "    \n",
    "    # Save remaining rows for training\n",
    "    df_train.to_csv(train_tsv, sep='\\t', index=False)\n",
    "    print(f\"Created {train_tsv} with remaining rows for training.\")\n",
    "else:\n",
    "    print(f\"{train_tsv} already exists. Skipping creation of the train file.\")\n",
    "\n",
    "# Original file remains unchanged\n",
    "print(f\"Original file {original_tsv} remains unchanged.\")\n",
    "\n",
    "# Check for common rows between test.tsv and train.tsv\n",
    "df1 = pd.read_csv(test_tsv, sep='\\t')\n",
    "df2 = pd.read_csv(train_tsv, sep='\\t')\n",
    "\n",
    "# Merge DataFrames to find common rows\n",
    "common_rows = pd.merge(df1, df2, how='inner')\n",
    "\n",
    "# Check if there are common rows\n",
    "if not common_rows.empty:\n",
    "    num_common_rows = len(common_rows)\n",
    "    print(f\"Error: There are {num_common_rows} common rows between {test_tsv} and {train_tsv}.\")\n",
    "else:\n",
    "    print(f\"No common rows found between {test_tsv} and {train_tsv}.\")\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropLoudest(object):\n",
    "    def __call__(self,tup):\n",
    "        audio, sr=tup\n",
    "        target_length=int(sr/2)\n",
    "        cs = np.cumsum(audio ** 2)\n",
    "        start = (cs[target_length:] - cs[:-target_length]).argmax()\n",
    "        return audio[start:start+target_length],sr\n",
    "\n",
    "class RecordingDataset(Dataset):\n",
    "  def __init__(self,tsvFile,soundFolder, transform=None):\n",
    "    self.table=pd.read_csv(tsvFile, sep='\\t', header=0)\n",
    "    self.table=self.table.drop(self.table.columns[0],axis=1)\n",
    "    self.table = self.table.dropna(subset=['gender'])\n",
    "\n",
    "    self.soundFolder=soundFolder\n",
    "\n",
    "    self.transform=transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.table)\n",
    "\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "   # print(self.table)\n",
    "    audioFile=os.path.join(self.soundFolder,self.table.iloc[index,0])\n",
    "    #sentence=self.table.iloc[index,2]\n",
    "    #age=self.table.iloc[index,6]\n",
    "    gender=self.table.iloc[index,7]\n",
    "    #accents=self.table.iloc[index,8]\n",
    "    #print(self.table.iloc[index,0])\n",
    "    #print(audioFile)\n",
    "    rawAudio,samplingRate = librosa.load(audioFile)\n",
    "    \n",
    "\n",
    "    collection=rawAudio, samplingRate\n",
    "    if gender==\"female_feminine\":\n",
    "        gender=0\n",
    "    else:\n",
    "        gender=1\n",
    "    if self.transform:\n",
    "      collection=self.transform(collection)\n",
    "    else:\n",
    "        print(\"THERE SHOULD BE TRANSFROM\")\n",
    "        return\n",
    "    return collection,gender\n",
    "\n",
    "\n",
    "class GetMfcc_channel1(object):\n",
    "\n",
    "\n",
    "    def __call__(self, collection):\n",
    "      \n",
    "        audio,sr=collection\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)  # Choosing 13 coefficients\n",
    "\n",
    "        # Normalize MFCCs\n",
    "        mfccs = librosa.util.normalize(mfccs)\n",
    "        mfccs = mfccs.reshape((mfccs.shape[0], mfccs.shape[1], 1))\n",
    "        #print(type(mfccs))\n",
    "        mfccs = np.transpose(mfccs, (2, 0, 1))\n",
    "\n",
    "        mfccs = torch.tensor(mfccs, dtype=torch.float32)\n",
    "        #print(mfccs.shape)\n",
    "\n",
    "        return mfccs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders,dataset_sizes,printEpoch,num_epochs=25):\n",
    "    since = time.time()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            if printEpoch:\n",
    "                print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    #print(\"Inputs Size:\",inputs.size())\n",
    "\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        #print(\"Outputs:\",outputs)\n",
    "                        #print(\"preds\",preds)\n",
    "                        #print(\"labels\",labels)\n",
    "\n",
    "                        #print(outputs,labels)\n",
    "                       \n",
    "\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                if phase == 'train':\n",
    "                    train_losses.append(epoch_loss)\n",
    "                    train_accuracies.append(epoch_acc)\n",
    "                else:\n",
    "                    val_losses.append(epoch_loss)\n",
    "                    val_accuracies.append(epoch_acc)\n",
    "\n",
    "                if printEpoch:\n",
    "                    print('-' * 10)\n",
    "                    print(f'{phase} Running Loss: {running_loss:.4f} Dataset Size: { dataset_sizes[phase]}')\n",
    "                    print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            #print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model,best_acc, train_losses, train_accuracies, val_losses, val_accuracies,time_elapsed\n",
    "\n",
    "def get_next_model_id():\n",
    "    model_files = [f for f in os.listdir('.') if re.match(r'models\\d+\\.pth', f)]\n",
    "    if not model_files:\n",
    "        return 1\n",
    "    existing_ids = sorted([int(re.search(r'models(\\d+)\\.pth', f).group(1)) for f in model_files])\n",
    "    if existing_ids:\n",
    "        next_id = existing_ids[-1] + 1\n",
    "    else:\n",
    "        next_id = 1\n",
    "    return next_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_metrics(train_losses, train_accuracies, val_losses, val_accuracies,totalTime):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    print(f'Training complete in {totalTime // 60:.0f}m {totalTime % 60:.0f}s')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plotting losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting accuracies\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_accuracies, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YourCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3,padding=1)#13,22\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=2)#12,21\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=1)#10,19\n",
    "        self.conv3 = nn.Conv2d(32,32,kernel_size=3,padding=1)#10,19\n",
    "        self.conv4 = nn.Conv2d(32,64,kernel_size=2)#9,18\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3,stride=1)#7,16\n",
    "        self.fc1 = nn.Linear(7*16*64, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "YourCNN                                  [4, 2]                    --\n",
       "├─Conv2d: 1-1                            [4, 16, 13, 22]           160\n",
       "├─Conv2d: 1-2                            [4, 32, 12, 21]           2,080\n",
       "├─MaxPool2d: 1-3                         [4, 32, 10, 19]           --\n",
       "├─Conv2d: 1-4                            [4, 32, 10, 19]           9,248\n",
       "├─Conv2d: 1-5                            [4, 64, 9, 18]            8,256\n",
       "├─MaxPool2d: 1-6                         [4, 64, 7, 16]            --\n",
       "├─Linear: 1-7                            [4, 2]                    14,338\n",
       "==========================================================================================\n",
       "Total params: 34,082\n",
       "Trainable params: 34,082\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 14.72\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.93\n",
       "Params size (MB): 0.14\n",
       "Estimated Total Size (MB): 1.07\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YourCNN()\n",
    "batch_size=4\n",
    "summary(model, input_size=(batch_size, 1, 13, 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def CompleteTrain(crit=nn.CrossEntropyLoss(),printEpoch=True,opt=\"SGD\",numb=0.9,lr=0.001):\n",
    "    getMfcc = GetMfcc_channel1()\n",
    "    crop=CropLoudest()\n",
    "    transformers=[crop,getMfcc,]\n",
    "    myTransforms=transforms.Compose(transformers)\n",
    "    TrainDataset=RecordingDataset(soundFolder=\"2000clips\",tsvFile=\"train.tsv\",transform=myTransforms)\n",
    "    TestDataset=RecordingDataset(soundFolder=\"2000clips\",tsvFile=\"test.tsv\",transform=myTransforms)\n",
    "\n",
    "\n",
    "    valLoader = DataLoader(TestDataset, batch_size=4,\n",
    "                            shuffle=False, num_workers=0)\n",
    "    trainLoader = DataLoader(TrainDataset, batch_size=4,\n",
    "                            shuffle=True, num_workers=0)\n",
    "    dataloaders = {\"train\":trainLoader,\"val\":valLoader}\n",
    "    dataset_sizes = {'train': len(TrainDataset), 'val': len(TestDataset)}\n",
    "    model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "    \n",
    "    model_conv=YourCNN()\n",
    "    model_conv = model_conv.to(device)\n",
    "    \n",
    "    if opt==\"SGD\":\n",
    "        optimizer_conv = optim.SGD(model_conv.parameters(), lr=lr, momentum=numb)\n",
    "    elif opt==\"ADAM\":\n",
    "        optimizer_conv = optim.Adam(model_conv.parameters(), lr=lr,weight_decay=numb)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "    model_conv,best_acc, train_losses, train_accuracies, val_losses, val_accuracies,totalTime = train_model(model_conv, crit, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25,dataloaders=dataloaders,dataset_sizes=dataset_sizes,printEpoch=printEpoch)\n",
    "    \n",
    "    \n",
    "    train_accuracies = [tensor.item() for tensor in train_accuracies]\n",
    "    val_accuracies = [tensor.item() for tensor in val_accuracies]\n",
    "\n",
    "    #plot_metrics(train_losses, train_accuracies, val_losses, val_accuracies,totalTime)\n",
    "\n",
    "    model_id = get_next_model_id()\n",
    "    with open('Results.tsv', 'a') as f:\n",
    "        f.write(f\"{opt}\\t{numb}\\t{lr}\\t{best_acc}\\t{totalTime}\\t{model_id}\\t\")\n",
    "        f.write(\",\".join(map(str, train_losses)) + \"\\t\")\n",
    "        f.write(\",\".join(map(str, train_accuracies)) + \"\\t\")\n",
    "        f.write(\",\".join(map(str, val_losses)) + \"\\t\")\n",
    "        f.write(\",\".join(map(str, val_accuracies)) + \"\\n\")\n",
    "        \n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model_conv.state_dict(), f\"models{model_id}.pth\")\n",
    "\n",
    "\n",
    "    return model_conv,best_acc,model_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m CompleteTrain(printEpoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADAM\u001b[39m\u001b[38;5;124m\"\u001b[39m,numb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 28\u001b[0m, in \u001b[0;36mCompleteTrain\u001b[1;34m(crit, printEpoch, opt, numb, lr)\u001b[0m\n\u001b[0;32m     25\u001b[0m     optimizer_conv \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_conv\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr,weight_decay\u001b[38;5;241m=\u001b[39mnumb)\n\u001b[0;32m     26\u001b[0m exp_lr_scheduler \u001b[38;5;241m=\u001b[39m lr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_conv, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m model_conv,best_acc, train_losses, train_accuracies, val_losses, val_accuracies,totalTime \u001b[38;5;241m=\u001b[39m train_model(model_conv, crit, optimizer_conv,\n\u001b[0;32m     29\u001b[0m                      exp_lr_scheduler, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,dataloaders\u001b[38;5;241m=\u001b[39mdataloaders,dataset_sizes\u001b[38;5;241m=\u001b[39mdataset_sizes,printEpoch\u001b[38;5;241m=\u001b[39mprintEpoch)\n\u001b[0;32m     32\u001b[0m train_accuracies \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m train_accuracies]\n\u001b[0;32m     33\u001b[0m val_accuracies \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m val_accuracies]\n",
      "Cell \u001b[1;32mIn[15], line 100\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, printEpoch, num_epochs)\u001b[0m\n\u001b[0;32m     97\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[phase]:\n\u001b[0;32m    101\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    102\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[15], line 41\u001b[0m, in \u001b[0;36mRecordingDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     39\u001b[0m     gender\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 41\u001b[0m   collection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(collection)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTHERE SHOULD BE TRANSFROM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "Cell \u001b[1;32mIn[15], line 54\u001b[0m, in \u001b[0;36mGetMfcc_channel1.__call__\u001b[1;34m(self, collection)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, collection):\n\u001b[0;32m     53\u001b[0m     audio,sr\u001b[38;5;241m=\u001b[39mcollection\n\u001b[1;32m---> 54\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)  \u001b[38;5;66;03m# Choosing 13 coefficients\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Normalize MFCCs\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mnormalize(mfccs)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\librosa\\feature\\spectral.py:1989\u001b[0m, in \u001b[0;36mmfcc\u001b[1;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m \n\u001b[0;32m   1845\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[0;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(melspectrogram(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m   1991\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfftpack\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[0;32m   1993\u001b[0m ]\n\u001b[0;32m   1995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lifter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;66;03m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\librosa\\feature\\spectral.py:2130\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmelspectrogram\u001b[39m(\n\u001b[0;32m   2009\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2010\u001b[0m     y: Optional[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2020\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   2021\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m \n\u001b[0;32m   2024\u001b[0m \u001b[38;5;124;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;124;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2130\u001b[0m     S, n_fft \u001b[38;5;241m=\u001b[39m _spectrogram(\n\u001b[0;32m   2131\u001b[0m         y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2132\u001b[0m         S\u001b[38;5;241m=\u001b[39mS,\n\u001b[0;32m   2133\u001b[0m         n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[0;32m   2134\u001b[0m         hop_length\u001b[38;5;241m=\u001b[39mhop_length,\n\u001b[0;32m   2135\u001b[0m         power\u001b[38;5;241m=\u001b[39mpower,\n\u001b[0;32m   2136\u001b[0m         win_length\u001b[38;5;241m=\u001b[39mwin_length,\n\u001b[0;32m   2137\u001b[0m         window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[0;32m   2138\u001b[0m         center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[0;32m   2139\u001b[0m         pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[0;32m   2140\u001b[0m     )\n\u001b[0;32m   2142\u001b[0m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[0;32m   2143\u001b[0m     mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\librosa\\core\\spectrum.py:2945\u001b[0m, in \u001b[0;36m_spectrogram\u001b[1;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[0;32m   2941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2942\u001b[0m         )\n\u001b[0;32m   2943\u001b[0m     S \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2944\u001b[0m         np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[1;32m-> 2945\u001b[0m             stft(\n\u001b[0;32m   2946\u001b[0m                 y,\n\u001b[0;32m   2947\u001b[0m                 n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[0;32m   2948\u001b[0m                 hop_length\u001b[38;5;241m=\u001b[39mhop_length,\n\u001b[0;32m   2949\u001b[0m                 win_length\u001b[38;5;241m=\u001b[39mwin_length,\n\u001b[0;32m   2950\u001b[0m                 center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[0;32m   2951\u001b[0m                 window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[0;32m   2952\u001b[0m                 pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[0;32m   2953\u001b[0m             )\n\u001b[0;32m   2954\u001b[0m         )\n\u001b[0;32m   2955\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m power\n\u001b[0;32m   2956\u001b[0m     )\n\u001b[0;32m   2958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\librosa\\core\\spectrum.py:241\u001b[0m, in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# Check audio is valid\u001b[39;00m\n\u001b[0;32m    239\u001b[0m util\u001b[38;5;241m.\u001b[39mvalid_audio(y, mono\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 241\u001b[0m fft_window \u001b[38;5;241m=\u001b[39m get_window(window, win_length, fftbins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# Pad the window out to n_fft size\u001b[39;00m\n\u001b[0;32m    244\u001b[0m fft_window \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mpad_center(fft_window, size\u001b[38;5;241m=\u001b[39mn_fft)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\librosa\\filters.py:1230\u001b[0m, in \u001b[0;36mget_window\u001b[1;34m(window, Nx, fftbins)\u001b[0m\n\u001b[0;32m   1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m window(Nx)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(window, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(window):\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;66;03m# TODO: if we add custom window functions in librosa, call them here\u001b[39;00m\n\u001b[1;32m-> 1230\u001b[0m     win: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mget_window(window, Nx, fftbins\u001b[38;5;241m=\u001b[39mfftbins)\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m win\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(window, (np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\scipy\\signal\\windows\\_windows.py:2374\u001b[0m, in \u001b[0;36mget_window\u001b[1;34m(window, Nx, fftbins)\u001b[0m\n\u001b[0;32m   2371\u001b[0m     winfunc \u001b[38;5;241m=\u001b[39m kaiser\n\u001b[0;32m   2372\u001b[0m     params \u001b[38;5;241m=\u001b[39m (Nx, beta)\n\u001b[1;32m-> 2374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m winfunc(\u001b[38;5;241m*\u001b[39mparams, sym\u001b[38;5;241m=\u001b[39msym)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\scipy\\signal\\windows\\_windows.py:804\u001b[0m, in \u001b[0;36mhann\u001b[1;34m(M, sym)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;124;03mReturn a Hann window.\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    801\u001b[0m \n\u001b[0;32m    802\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# Docstring adapted from NumPy's hanning function\u001b[39;00m\n\u001b[1;32m--> 804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m general_hamming(M, \u001b[38;5;241m0.5\u001b[39m, sym)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\scipy\\signal\\windows\\_windows.py:1033\u001b[0m, in \u001b[0;36mgeneral_hamming\u001b[1;34m(M, alpha, sym)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgeneral_hamming\u001b[39m(M, alpha, sym\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    948\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return a generalized Hamming window.\u001b[39;00m\n\u001b[0;32m    949\u001b[0m \n\u001b[0;32m    950\u001b[0m \u001b[38;5;124;03m    The generalized Hamming window is constructed by multiplying a rectangular\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \n\u001b[0;32m   1032\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1033\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m general_cosine(M, [alpha, \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m alpha], sym)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\scipy\\signal\\windows\\_windows.py:120\u001b[0m, in \u001b[0;36mgeneral_cosine\u001b[1;34m(M, a, sym)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mones(M)\n\u001b[0;32m    118\u001b[0m M, needs_trunc \u001b[38;5;241m=\u001b[39m _extend(M, sym)\n\u001b[1;32m--> 120\u001b[0m fac \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi, np\u001b[38;5;241m.\u001b[39mpi, M)\n\u001b[0;32m    121\u001b[0m w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(M)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(a)):\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\numpy\\core\\function_base.py:182\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), step\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CompleteTrain(printEpoch=False,opt=\"ADAM\",numb=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 8m 17s\n",
      "Best val Acc: 0.781000\n",
      "Model1 trained\n",
      "Training complete in 8m 54s\n",
      "Best val Acc: 0.668000\n",
      "Model2 trained\n",
      "Training complete in 9m 14s\n",
      "Best val Acc: 0.668000\n",
      "Model3 trained\n",
      "Training complete in 9m 14s\n",
      "Best val Acc: 0.840000\n",
      "Model4 trained\n",
      "Training complete in 8m 45s\n",
      "Best val Acc: 0.500000\n",
      "Model5 trained\n",
      "Training complete in 8m 41s\n",
      "Best val Acc: 0.704000\n",
      "Model6 trained\n",
      "Training complete in 9m 48s\n",
      "Best val Acc: 0.795000\n",
      "Model7 trained\n",
      "Training complete in 9m 18s\n",
      "Best val Acc: 0.778000\n",
      "Model8 trained\n",
      "Training complete in 9m 15s\n",
      "Best val Acc: 0.786000\n",
      "Model9 trained\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m         bestId\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wDecay \u001b[38;5;129;01min\u001b[39;00m ADAMnumb:\n\u001b[1;32m---> 14\u001b[0m     _,ac,\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mCompleteTrain(opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADAM\u001b[39m\u001b[38;5;124m\"\u001b[39m,numb\u001b[38;5;241m=\u001b[39mwDecay,lr\u001b[38;5;241m=\u001b[39ml,printEpoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trained\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(ac\u001b[38;5;241m>\u001b[39mbestAc):\n",
      "Cell \u001b[1;32mIn[21], line 28\u001b[0m, in \u001b[0;36mCompleteTrain\u001b[1;34m(crit, printEpoch, opt, numb, lr)\u001b[0m\n\u001b[0;32m     25\u001b[0m     optimizer_conv \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_conv\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr,weight_decay\u001b[38;5;241m=\u001b[39mnumb)\n\u001b[0;32m     26\u001b[0m exp_lr_scheduler \u001b[38;5;241m=\u001b[39m lr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_conv, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m model_conv,best_acc, train_losses, train_accuracies, val_losses, val_accuracies,totalTime \u001b[38;5;241m=\u001b[39m train_model(model_conv, crit, optimizer_conv,\n\u001b[0;32m     29\u001b[0m                      exp_lr_scheduler, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,dataloaders\u001b[38;5;241m=\u001b[39mdataloaders,dataset_sizes\u001b[38;5;241m=\u001b[39mdataset_sizes,printEpoch\u001b[38;5;241m=\u001b[39mprintEpoch)\n\u001b[0;32m     32\u001b[0m train_accuracies \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m train_accuracies]\n\u001b[0;32m     33\u001b[0m val_accuracies \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m val_accuracies]\n",
      "Cell \u001b[1;32mIn[15], line 100\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, printEpoch, num_epochs)\u001b[0m\n\u001b[0;32m     97\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[phase]:\n\u001b[0;32m    101\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    102\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[15], line 41\u001b[0m, in \u001b[0;36mRecordingDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     39\u001b[0m     gender\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 41\u001b[0m   collection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(collection)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTHERE SHOULD BE TRANSFROM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "Cell \u001b[1;32mIn[15], line 54\u001b[0m, in \u001b[0;36mGetMfcc_channel1.__call__\u001b[1;34m(self, collection)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, collection):\n\u001b[0;32m     53\u001b[0m     audio,sr\u001b[38;5;241m=\u001b[39mcollection\n\u001b[1;32m---> 54\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)  \u001b[38;5;66;03m# Choosing 13 coefficients\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Normalize MFCCs\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mnormalize(mfccs)\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\librosa\\feature\\spectral.py:1989\u001b[0m, in \u001b[0;36mmfcc\u001b[1;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m \n\u001b[0;32m   1845\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[0;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(melspectrogram(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m   1991\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfftpack\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[0;32m   1993\u001b[0m ]\n\u001b[0;32m   1995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lifter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;66;03m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\librosa\\feature\\spectral.py:2143\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2130\u001b[0m S, n_fft \u001b[38;5;241m=\u001b[39m _spectrogram(\n\u001b[0;32m   2131\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2132\u001b[0m     S\u001b[38;5;241m=\u001b[39mS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2139\u001b[0m     pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[0;32m   2140\u001b[0m )\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m-> 2143\u001b[0m mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2145\u001b[0m melspec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...ft,mf->...mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, S, mel_basis, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "File \u001b[1;32mc:\\Users\\oguzhan.kaya\\AppData\\Local\\anaconda3\\envs\\myenv\\Lib\\site-packages\\librosa\\filters.py:239\u001b[0m, in \u001b[0;36mmel\u001b[1;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[0;32m    236\u001b[0m     upper \u001b[38;5;241m=\u001b[39m ramps[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m fdiff[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# .. then intersect them with each other and zero\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     weights[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39mminimum(lower, upper))\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(norm, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslaney\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# Slaney-style mel is scaled to be approx constant energy per channel\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SGDnumb=[0.9,0.5,0.09]\n",
    "ADAMnumb=[0.001,0.005]\n",
    "lr=[0.001,0.005,0.01]\n",
    "bestAc=0\n",
    "bestId=0\n",
    "for l in lr:\n",
    "    for momentum in SGDnumb:\n",
    "        _,ac,id=CompleteTrain(opt=\"SGD\",numb=momentum,lr=l,printEpoch=False)\n",
    "        print(f\"Model{id} trained\")\n",
    "        if(ac>bestAc):\n",
    "            bestAc=ac\n",
    "            bestId=id\n",
    "    for wDecay in ADAMnumb:\n",
    "        _,ac,id=CompleteTrain(opt=\"ADAM\",numb=wDecay,lr=l,printEpoch=False)\n",
    "        print(f\"Model{id} trained\")\n",
    "        if(ac>bestAc):\n",
    "            bestAc=ac\n",
    "            bestId=id\n",
    "print(f\"Best ID: {bestId} Best Ac: {bestAc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Running Loss: 671.5389 Dataset Size: 1000\n",
      "train Loss: 0.6715 Acc: 0.5650\n",
      "----------\n",
      "val Running Loss: 603.7663 Dataset Size: 1000\n",
      "val Loss: 0.6038 Acc: 0.6850\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Running Loss: 567.2319 Dataset Size: 1000\n",
      "train Loss: 0.5672 Acc: 0.7210\n",
      "----------\n",
      "val Running Loss: 589.3770 Dataset Size: 1000\n",
      "val Loss: 0.5894 Acc: 0.6620\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Running Loss: 515.2654 Dataset Size: 1000\n",
      "train Loss: 0.5153 Acc: 0.7410\n",
      "----------\n",
      "val Running Loss: 645.2785 Dataset Size: 1000\n",
      "val Loss: 0.6453 Acc: 0.6720\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Running Loss: 516.5610 Dataset Size: 1000\n",
      "train Loss: 0.5166 Acc: 0.7460\n",
      "----------\n",
      "val Running Loss: 476.5856 Dataset Size: 1000\n",
      "val Loss: 0.4766 Acc: 0.7860\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Running Loss: 475.8352 Dataset Size: 1000\n",
      "train Loss: 0.4758 Acc: 0.7660\n",
      "----------\n",
      "val Running Loss: 458.9945 Dataset Size: 1000\n",
      "val Loss: 0.4590 Acc: 0.7910\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Running Loss: 440.5096 Dataset Size: 1000\n",
      "train Loss: 0.4405 Acc: 0.8000\n",
      "----------\n",
      "val Running Loss: 492.4582 Dataset Size: 1000\n",
      "val Loss: 0.4925 Acc: 0.7780\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Running Loss: 439.3252 Dataset Size: 1000\n",
      "train Loss: 0.4393 Acc: 0.8010\n",
      "----------\n",
      "val Running Loss: 417.4289 Dataset Size: 1000\n",
      "val Loss: 0.4174 Acc: 0.8120\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Running Loss: 378.0157 Dataset Size: 1000\n",
      "train Loss: 0.3780 Acc: 0.8490\n",
      "----------\n",
      "val Running Loss: 398.4286 Dataset Size: 1000\n",
      "val Loss: 0.3984 Acc: 0.8260\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Running Loss: 369.2048 Dataset Size: 1000\n",
      "train Loss: 0.3692 Acc: 0.8350\n",
      "----------\n",
      "val Running Loss: 394.0135 Dataset Size: 1000\n",
      "val Loss: 0.3940 Acc: 0.8270\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Running Loss: 366.5463 Dataset Size: 1000\n",
      "train Loss: 0.3665 Acc: 0.8450\n",
      "----------\n",
      "val Running Loss: 393.3874 Dataset Size: 1000\n",
      "val Loss: 0.3934 Acc: 0.8230\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Running Loss: 365.8851 Dataset Size: 1000\n",
      "train Loss: 0.3659 Acc: 0.8570\n",
      "----------\n",
      "val Running Loss: 391.1849 Dataset Size: 1000\n",
      "val Loss: 0.3912 Acc: 0.8280\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Running Loss: 364.7671 Dataset Size: 1000\n",
      "train Loss: 0.3648 Acc: 0.8400\n",
      "----------\n",
      "val Running Loss: 399.5645 Dataset Size: 1000\n",
      "val Loss: 0.3996 Acc: 0.8220\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Running Loss: 362.6193 Dataset Size: 1000\n",
      "train Loss: 0.3626 Acc: 0.8530\n",
      "----------\n",
      "val Running Loss: 386.3914 Dataset Size: 1000\n",
      "val Loss: 0.3864 Acc: 0.8340\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Running Loss: 356.1354 Dataset Size: 1000\n",
      "train Loss: 0.3561 Acc: 0.8580\n",
      "----------\n",
      "val Running Loss: 392.5825 Dataset Size: 1000\n",
      "val Loss: 0.3926 Acc: 0.8230\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Running Loss: 351.4424 Dataset Size: 1000\n",
      "train Loss: 0.3514 Acc: 0.8570\n",
      "----------\n",
      "val Running Loss: 384.2868 Dataset Size: 1000\n",
      "val Loss: 0.3843 Acc: 0.8340\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Running Loss: 350.9872 Dataset Size: 1000\n",
      "train Loss: 0.3510 Acc: 0.8550\n",
      "----------\n",
      "val Running Loss: 384.2826 Dataset Size: 1000\n",
      "val Loss: 0.3843 Acc: 0.8320\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Running Loss: 350.0290 Dataset Size: 1000\n",
      "train Loss: 0.3500 Acc: 0.8540\n",
      "----------\n",
      "val Running Loss: 385.2609 Dataset Size: 1000\n",
      "val Loss: 0.3853 Acc: 0.8350\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Running Loss: 350.3553 Dataset Size: 1000\n",
      "train Loss: 0.3504 Acc: 0.8570\n",
      "----------\n",
      "val Running Loss: 384.1442 Dataset Size: 1000\n",
      "val Loss: 0.3841 Acc: 0.8320\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Running Loss: 349.9630 Dataset Size: 1000\n",
      "train Loss: 0.3500 Acc: 0.8540\n",
      "----------\n",
      "val Running Loss: 384.1108 Dataset Size: 1000\n",
      "val Loss: 0.3841 Acc: 0.8330\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Running Loss: 349.7166 Dataset Size: 1000\n",
      "train Loss: 0.3497 Acc: 0.8560\n",
      "----------\n",
      "val Running Loss: 384.2811 Dataset Size: 1000\n",
      "val Loss: 0.3843 Acc: 0.8370\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Running Loss: 349.4304 Dataset Size: 1000\n",
      "train Loss: 0.3494 Acc: 0.8560\n",
      "----------\n",
      "val Running Loss: 383.9340 Dataset Size: 1000\n",
      "val Loss: 0.3839 Acc: 0.8340\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Running Loss: 348.4536 Dataset Size: 1000\n",
      "train Loss: 0.3485 Acc: 0.8580\n",
      "----------\n",
      "val Running Loss: 383.9158 Dataset Size: 1000\n",
      "val Loss: 0.3839 Acc: 0.8340\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Running Loss: 348.4444 Dataset Size: 1000\n",
      "train Loss: 0.3484 Acc: 0.8580\n",
      "----------\n",
      "val Running Loss: 383.9109 Dataset Size: 1000\n",
      "val Loss: 0.3839 Acc: 0.8340\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Running Loss: 348.4272 Dataset Size: 1000\n",
      "train Loss: 0.3484 Acc: 0.8580\n",
      "----------\n",
      "val Running Loss: 383.9018 Dataset Size: 1000\n",
      "val Loss: 0.3839 Acc: 0.8340\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Running Loss: 348.3576 Dataset Size: 1000\n",
      "train Loss: 0.3484 Acc: 0.8600\n",
      "----------\n",
      "val Running Loss: 383.9032 Dataset Size: 1000\n",
      "val Loss: 0.3839 Acc: 0.8330\n",
      "Training complete in 8m 13s\n",
      "Best val Acc: 0.837000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(YourCNN(\n",
       "   (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (conv2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
       "   (maxpool1): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "   (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (conv4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "   (maxpool2): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "   (fc1): Linear(in_features=7168, out_features=2, bias=True)\n",
       " ),\n",
       " tensor(0.8370, device='cuda:0', dtype=torch.float64),\n",
       " 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompleteTrain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
